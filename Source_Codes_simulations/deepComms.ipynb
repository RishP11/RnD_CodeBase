{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**deepComms**<br>\n",
    "By $\\text{Rishabh Pomaje}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Autoencoder based SISO system.\n",
    "- Objectives :\n",
    "    - To learn a (4, 7) code system under the following conditions :\n",
    "    1. AWGN channel\n",
    "    2. Channel noise : $Y = X + W$\n",
    "        - where, $W \\overset{i.i.d}{\\sim} \\mathcal{CN}(0,N_0)$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies :\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "%config InlineBackend.figure_format='svg' # Comment for faster plot rendering\n",
    "print(tf.__version__)\n",
    "TF_ENABLE_ONEDNN_OPTS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using the following definition of SNR :\n",
    "\\begin{equation}\n",
    "\\text{SNR}_{linear} = \\frac{E_b}{N_0} = \\frac{\\text{Tx. Signal Power per bit}}{\\text{Noise Variance}}\n",
    "\\end{equation}\n",
    "- Per bit energies :\n",
    "- BPSK : {$\\pm \\sqrt{E_{b}}$}\n",
    "- $E_{uncoded} = 1$\n",
    "\\begin{equation}\n",
    "E_{coded} = E_{uncoded} \\times k / n = E_{uncoded} \\times R\n",
    "\\end{equation}\n",
    "- $R$ = Information Rate \n",
    "- $\\color{red}{Note}$ : This difference in energy per bit needs to be compensated in either symbol energy or the noise variance. I have arbitrarily chosen it to be the noise variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- System Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 2 ** 4        # Size of alphabet                     \n",
    "k = np.log2(M)    # Number of bits required           \n",
    "n = 7             # Block length of coded vector    \n",
    "R = k / n         # Communication rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generation of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_size = 10 ** 6 \n",
    "sample_indices = np.random.randint(0, M, training_data_size)\n",
    "\n",
    "# Set of One Hot Encoded Vectors :\n",
    "x_train = []\n",
    "for idx in sample_indices:\n",
    "    temp = np.zeros(M)\n",
    "    temp[idx] = 1\n",
    "    x_train.append(temp)\n",
    "x_train = tf.constant(x_train)\n",
    "\n",
    "# Labels for the data :\n",
    "# Since we want to reproduce the input at the output :\n",
    "y_train = x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating the Auto-Encoder Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the encoder layers :\n",
    "enc_input_layer = tf.keras.Input(shape=(M,), name='Input Layer')\n",
    "enc_layer_01 = tf.keras.layers.Dense(M, activation='relu', name='Encoder_Hidden_01')(enc_input_layer)\n",
    "enc_layer_02 = tf.keras.layers.Dense(n, activation='linear', name='Encoder_Hidden_02')(enc_layer_01)\n",
    "enc_layer_normalized = tf.keras.layers.Lambda((lambda x: np.sqrt(n) * tf.keras.backend.l2_normalize(x, axis=-1)))(enc_layer_02)\n",
    "\n",
    "# Describing the channel layers :\n",
    "# Training SNR\n",
    "SNR_dB = 7                                       # Eb / N0 in dB scale\n",
    "SNR_lin = 10 ** (SNR_dB / 10)                    # In linear scale\n",
    "ch_noise_layer = tf.keras.layers.GaussianNoise(stddev=np.sqrt(1 / (2 * R * SNR_lin)), name='AWGN_channel')(enc_layer_normalized)\n",
    "\n",
    "# Describing the decoder layers :\n",
    "dec_layer_01 =  tf.keras.layers.Dense(M, activation='relu', name='Decoder_Hidden_01')(ch_noise_layer)\n",
    "dec_output_layer = tf.keras.layers.Dense(M, activation='softmax', name='Output_Layer')(dec_layer_01)\n",
    "\n",
    "autoencoder = tf.keras.Model(enc_input_layer,dec_output_layer)\n",
    "\n",
    "# Compiling the model :\n",
    "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to view the block diagram of the autoencoder :\n",
    "# tf.keras.utils.plot_model(\n",
    "#     autoencoder,\n",
    "#     to_file='images/deepComms.png',\n",
    "#     show_shapes=True,\n",
    "#     show_dtype=True,\n",
    "#     show_layer_names=True,\n",
    "#     rankdir='TB',\n",
    "#     expand_nested=True,\n",
    "#     dpi=200,\n",
    "#     show_layer_activations=True,\n",
    "#     show_trainable=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model by using training set :\n",
    "autoencoder.fit(x_train, y_train, batch_size=1000, epochs=250) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testing the above learned system for various SNRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder :\n",
    "encoder_model = tf.keras.Model(enc_input_layer, enc_layer_normalized)\n",
    "\n",
    "# Supposed received codeword at the receiver\n",
    "encoded_input = tf.keras.Input(shape=(n,))\n",
    "decoder_output = autoencoder.layers[-2](encoded_input)\n",
    "decoder_output = autoencoder.layers[-1](decoder_output)\n",
    "\n",
    "# Decoder :\n",
    "decoder_model = tf.keras.Model(encoded_input, decoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generation of validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size = 10 ** 6 # Number of Blocks \n",
    "y_test = np.random.randint(0, M, test_data_size)\n",
    "x_test = []\n",
    "for idx in y_test:\n",
    "    temp = np.zeros(M)\n",
    "    temp[idx] = 1\n",
    "    x_test.append(temp)\n",
    "\n",
    "x_test = tf.constant(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Validation Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of Signal to Noise Ratio a\n",
    "# in dB :\n",
    "SNR_dB = np.linspace(-4, 8, 25)\n",
    "# in Linear Scale :\n",
    "SNR_lin = 10 ** (SNR_dB / 10)\n",
    "# Fixing energy per bit :\n",
    "E_b = 1 \n",
    "# Range of noise variance accordingly :\n",
    "noise_var = 1 / (2 * R * SNR_lin) # This is the real noise only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLER_learned = []\n",
    "for noise in noise_var :\n",
    "    # Encoding \n",
    "    encoded_signal = encoder_model.predict(x_test)\n",
    "    # Noise\n",
    "    awgn = np.sqrt(noise) * np.random.normal(0, 1, (test_data_size, n))\n",
    "    rx_noisy_signal = encoded_signal + awgn\n",
    "    # Decoding \n",
    "    decoded_signal = decoder_model.predict(rx_noisy_signal)\n",
    "    estimated_vectors = np.argmax(decoded_signal, axis=-1)\n",
    "    BLER_learned.append(np.sum(estimated_vectors != y_test) / test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical system performance points :\n",
    "BLER_uncoded = [0.5619008, 0.5302992, 0.4980176, 0.464168, 0.428892, 0.391688, 0.3546936, 0.3168176, 0.279812, 0.2421696, 0.2067912, 0.1734344, 0.141828, 0.113588, 0.0882648, 0.0672608, 0.0489648, 0.0347752, 0.0235656, 0.0151792, 0.0094872, 0.0055928, 0.0031232, 0.0015888, 0.000768]\n",
    "BLER_coded_hard = [0.5549816, 0.5234256, 0.4893024, 0.4540144, 0.4175016, 0.3800856, 0.3407112, 0.3017352, 0.2632096, 0.224484, 0.1888416, 0.15496, 0.122672, 0.095972, 0.0725256, 0.0521936, 0.0365192, 0.0248592, 0.0157856, 0.009416, 0.0053832, 0.0028672, 0.0013296, 0.0006472, 0.00026]\n",
    "BLER_coded_MLD = [0.4865864, 0.4508992, 0.4131624, 0.3743584, 0.3348624, 0.2947384, 0.2544, 0.2163592, 0.1798328, 0.1453904, 0.1147968, 0.0872416, 0.063824, 0.0450768, 0.0302208, 0.0196504, 0.0117504, 0.0067432, 0.0036112, 0.0017864, 0.0008056, 0.000332, 0.000132, 3.2e-05, 1.04e-05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True, # Comment this if TeX is not available in your machine\n",
    "    \"font.family\" : 'serif',\n",
    "    \"font.size\": 12\n",
    "})\n",
    "\n",
    "fig, axes = plt.subplots()\n",
    "axes.semilogy(SNR_dB, BLER_uncoded, label=\"Uncoded\", c='black')\n",
    "axes.semilogy(SNR_dB, BLER_coded_hard, label=\"Hamming (7, 4) (Hard)\", c=\"blue\")\n",
    "axes.semilogy(SNR_dB, BLER_coded_MLD, label=\"Hamming (7, 4) (MLD)\", c=\"blue\", ls=\"--\")\n",
    "axes.semilogy(SNR_dB, BLER_learned, label=\"Learned\", c='red', marker='o', ls=\" \")\n",
    "axes.set_xlabel(r'$E_b / N_0[dB]$')\n",
    "axes.set_ylabel(r'$BLER$')\n",
    "axes.set_xlim(-4, 8)\n",
    "axes.set_ylim(10**-5, 10**0)\n",
    "axes.set_title(f'BLER Performance Comparison - BPSK')\n",
    "axes.legend()\n",
    "axes.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results for future reference\n",
    "fig.savefig(fname='plots/deepComms_7_4.svg', transparent=True)\n",
    "with open(\"results/results_deepComms_7_4.txt\", mode='w') as file_id :\n",
    "    file_id.write(f'BLER_uncoded = {BLER_uncoded}\\n')\n",
    "    file_id.write(f'BLER_coded_hard = {BLER_coded_hard}\\n')\n",
    "    file_id.write(f'BLER_coded_mld = {BLER_coded_MLD}\\n')\n",
    "    file_id.write(f'BLER_learned = {BLER_learned}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using this same model for performing manual coherent detection :\n",
    "\n",
    "- Here we take the output from encoder of the above learned system, then we simulate the fading and noise by ourselves. After that we do coherent detection. Then, the resultant signal is passed on to the decoder of the above learned system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLER_manual_coherent = []\n",
    "for noise in noise_var :\n",
    "    # Encoding using our model :\n",
    "    encoded_signal = encoder_model.predict(x_test)\n",
    "    # Fast fading effect :\n",
    "    fade_taps = np.random.normal(0, np.sqrt(0.5), (test_data_size, n)) + 1j* np.random.normal(0, np.sqrt(0.5), (test_data_size, n))\n",
    "    rx_faded_signal = fade_taps * encoded_signal\n",
    "    # Generating AWGN samples :\n",
    "    awgn = np.random.normal(0, np.sqrt(noise), (test_data_size, n)) + 1j* np.random.normal(0, np.sqrt(noise), (test_data_size, n))\n",
    "    rx_noisy_signal = rx_faded_signal + awgn \n",
    "    # Decoding using our model :\n",
    "    decoded_signal = decoder_model.predict(np.real(np.conjugate(fade_taps) * rx_noisy_signal / np.absolute(fade_taps)))\n",
    "    estimated_vectors = np.argmax(decoded_signal, axis=-1)\n",
    "    BLER_manual_coherent.append(np.sum(estimated_vectors != y_test) / test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison curves : These have been obtained by classical method simulations\n",
    "BLER_uncoded_coherent = [0.65215, 0.63525, 0.60991, 0.59174, 0.56693, 0.54118, 0.51972, 0.49274, 0.46816, 0.44209, 0.4198, 0.39144, 0.36744, 0.34496, 0.32022, 0.29818, 0.27314, 0.2568, 0.23292, 0.21127, 0.1964, 0.17721, 0.16392, 0.14737, 0.13511]\n",
    "BLER_coded_coherent_MLD = [0.58016, 0.55535, 0.52368, 0.49402, 0.46342, 0.43045, 0.39986, 0.36771, 0.33257, 0.29946, 0.26815, 0.23793, 0.20806, 0.18062, 0.15724, 0.13379, 0.11153, 0.09413, 0.07586, 0.0623, 0.05014, 0.04037, 0.03194, 0.02463, 0.01983]\n",
    "BLER_coded_coherent_Hard = [0.6366, 0.61527, 0.58994, 0.56438, 0.53288, 0.5114, 0.47843, 0.44857, 0.41948, 0.38905, 0.35984, 0.32792, 0.29742, 0.27081, 0.24346, 0.21354, 0.19237, 0.16746, 0.14807, 0.12968, 0.11011, 0.09618, 0.08048, 0.06702, 0.05804]\n",
    "# Plotting :\n",
    "fig, axes = plt.subplots()\n",
    "axes.semilogy(SNR_dB, BLER_uncoded_coherent, label=\"Uncoded\", c='black')\n",
    "axes.semilogy(SNR_dB, BLER_coded_coherent_Hard, label=\"Hamming (7, 4) (Hard)\", c=\"blue\", ls=\"-.\")\n",
    "axes.semilogy(SNR_dB, BLER_coded_coherent_MLD, label=\"Hamming (7, 4) (MLD)\", c=\"blue\", ls=\"--\")\n",
    "axes.semilogy(SNR_dB, BLER_manual_coherent, label=\"Learned\", c='red', marker='o', ls=\" \")\n",
    "axes.set_xlabel(r'$E_b / N_0[dB]$')\n",
    "axes.set_ylabel(r'$P_{BLE}$', rotation=0)\n",
    "axes.set_xlim(-4, 8)\n",
    "axes.set_ylim(10**-5, 10**0)\n",
    "axes.set_title(f'Learned Manual coherent detection - BPSK')\n",
    "axes.legend()\n",
    "axes.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results for future reference\n",
    "# Plots :\n",
    "fig.savefig(fname='plots/deepComms_7_4_manual_coherent.svg', transparent=True)\n",
    "# Values :\n",
    "with open(\"results/results_deepComms_7_4_manual_coherent.txt\", mode='w') as file_id :\n",
    "    file_id.write(\"BLER_uncoded_coherent = \")\n",
    "    file_id.write(f'{str(BLER_uncoded_coherent)}\\n')\n",
    "    file_id.write(\"BLER_coded_coherent_hard = \")\n",
    "    file_id.write(f'{str(BLER_coded_coherent_Hard)}\\n')\n",
    "    file_id.write(\"BLER_coded_coherent_MLD = \")\n",
    "    file_id.write(f'{str(BLER_coded_coherent_MLD)}\\n')\n",
    "    file_id.write(\"BLER_manual_coherent = \")\n",
    "    file_id.write(str(BLER_manual_coherent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
